import cv2
from det_face_mediapipe import FaceMeshDetector
from Eye_Control import EyeCtrl

def main():
    face_mesh_detector = FaceMeshDetector()
    eye_ctrl = EyeCtrl('COM5')  

    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        return

    # æ‘„åƒå¤´ç”»é¢å®½é«˜
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    while True:
        ret, frame = cap.read()
        if not ret:
            print("âŒ è¯»å–æ‘„åƒå¤´ç”»é¢å¤±è´¥")
            break

        cv2.imshow("frame", frame)

        # è·å–äººè„¸å…³é”®ç‚¹
        landmarks, blendshapes, rotation_matrix = face_mesh_detector.get_results(frame)

        if landmarks:
            try:
                # è®¡ç®—äººè„¸çš„æ°´å¹³å’Œç«–ç›´ä½ç½®ï¼Œè·Ÿè¸ªäººè„¸ç§»åŠ¨
                face_center_x = (landmarks[33].x + landmarks[263].x) / 2  # å–å·¦ã€å³çœ¼çš„æ°´å¹³ä¸­ç‚¹
                face_center_y = (landmarks[33].y + landmarks[263].y) / 2  # å–å·¦ã€å³çœ¼çš„ç«–ç›´ä¸­ç‚¹

                # æ§åˆ¶çœ¼çƒæ°´å¹³å’Œç«–ç›´ä½ç½®
                horizontal_offset = max(0.0, min(1.0, (0.7 - face_center_x) * 2.5))
                vertical_offset = max(0.0, min(1.0, (0.7 - face_center_y) * 3.0))

                eye_ctrl.eyeball_horizontal = horizontal_offset
                eye_ctrl.eyeball_vertical = vertical_offset
                eye_ctrl.send()

                print(f"ğŸ‘ï¸ æ§åˆ¶:çœ¼çƒæ°´å¹³:{horizontal_offset:.2f} ç«–ç›´:{vertical_offset:.2f}")

            except Exception as e:
                print(f"[æ§åˆ¶ä¼ºæœå¼‚å¸¸] {e}")
        else:
            print("ğŸ˜ æ²¡æ£€æµ‹åˆ°äººè„¸")

        # æ— è®ºæ˜¯å¦æ£€æµ‹åˆ°äººè„¸éƒ½æ˜¾ç¤ºç”»é¢
        # cv2.imshow("Face Tracking", cv2.flip(frame, 1))

        # æŒ‰ q é€€å‡º
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()


if __name__ == "__main__":
    main()
